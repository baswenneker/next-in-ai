{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Set the environment variables/settings.\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload\n",
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass('Enter your paid OpenAI API key here (go to https://platform.openai.com/account/api-keys):')\n",
        "\n",
        "# Get it here: https://help.getpocket.com/article/1074-can-i-subscribe-to-my-list-via-rss\n",
        "os.environ['POCKET_RSS_FEED'] =\"https://getpocket.com/users/*sso1456990609615e33/feed/all\"\n",
        "\n",
        "# Beehiiv newsletter page (used to determine which Pocket articles are fetched).\n",
        "# Leave empty to get all articles from the last 7 days.\n",
        "# For example: \"https://nextinai.beehiiv.com/\"\n",
        "os.environ['BEEHIIV_URL']=''\n",
        "\n",
        "# Use \"gpt-3.5-turbo\" (default) or \"gpt-4\". GPT-4 gives the best results, but is more expensive.\n",
        "os.environ['MODEL'] = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Leave empty for English:\n",
        "os.environ['OUTPUT_LANGUAGE'] =\"Dutch\" \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAmEALajYmAO",
        "outputId": "9ff7c2b6-2cd1-4333-d5e6-ef52a5afa64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Enter your paid OpenAI API key here (go to https://platform.openai.com/account/api-keys):¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4_4EIWLWLhA",
        "outputId": "91d91014-c82c-4619-f312-69b2bea2120a",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'next-in-ai'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 92 (delta 48), reused 80 (delta 36), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (92/92), 67.87 KiB | 1.51 MiB/s, done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: readtime in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 5)) (0.8.11)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (0.27.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 8)) (4.11.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 9)) (2022.7.1)\n",
            "Requirement already satisfied: trafilatura in /usr/local/lib/python3.10/dist-packages (from -r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/next-in-ai/.devcontainer/requirements.txt (line 2)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r /content/next-in-ai/.devcontainer/requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: markdown2>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from readtime->-r /content/next-in-ai/.devcontainer/requirements.txt (line 4)) (2.4.8)\n",
            "Requirement already satisfied: pyquery>=1.2 in /usr/local/lib/python3.10/dist-packages (from readtime->-r /content/next-in-ai/.devcontainer/requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx->-r /content/next-in-ai/.devcontainer/requirements.txt (line 5)) (4.9.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (4.65.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->-r /content/next-in-ai/.devcontainer/requirements.txt (line 8)) (2.4.1)\n",
            "Requirement already satisfied: justext>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: courlan>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (0.9.2)\n",
            "Requirement already satisfied: htmldate>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (1.2.3)\n",
            "Requirement already satisfied: langcodes>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=0.7.2->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (3.3.0)\n",
            "Requirement already satisfied: tld>=0.13 in /usr/local/lib/python3.10/dist-packages (from courlan>=0.7.2->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (0.13)\n",
            "Requirement already satisfied: dateparser>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.2.1->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (1.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from htmldate>=1.2.1->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (2.8.2)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyquery>=1.2->readtime->-r /content/next-in-ai/.devcontainer/requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r /content/next-in-ai/.devcontainer/requirements.txt (line 7)) (4.0.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.1->htmldate>=1.2.1->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (4.3)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.1->htmldate>=1.2.1->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (2022.10.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->htmldate>=1.2.1->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->dateparser>=1.1.1->htmldate>=1.2.1->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->dateparser>=1.1.1->htmldate>=1.2.1->trafilatura->-r /content/next-in-ai/.devcontainer/requirements.txt (line 10)) (2023.3)\n"
          ]
        }
      ],
      "source": [
        "#@title Set up the environment and download requirements.\n",
        "\n",
        "!rm -rf /content/next-in-ai/\n",
        "!git clone https://github.com/baswenneker/next-in-ai.git\n",
        "\n",
        "!pip install -r /content/next-in-ai/.devcontainer/requirements.txt\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, \"/content/next-in-ai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to fetch the urls from Pocket."
      ],
      "metadata": {
        "id": "qiJ8WCsh-k6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fetch new Pocket article urls.\n",
        "\n",
        "%autoreload\n",
        "from next_in_ai.PocketParser import PocketParser\n",
        "\n",
        "p = PocketParser()\n",
        "\n",
        "# Get all Pocket urls since you sent out the last newsletter (works with Beehiiv):\n",
        "# latest_pocket_urls = p.new_articles()\n",
        "# Get all Pocket urls added since 7 days:\n",
        "latest_pocket_urls = p.new_articles_from_days_ago(7)\n",
        "\n",
        "print(\"We got the following URLs from Pocket:\")\n",
        "\n",
        "for url in latest_pocket_urls:\n",
        "  print(f\" - {url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-1eaIbeaY67",
        "outputId": "0a0bddd2-9be6-454f-f4ca-b3ef9bff1243",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We got the following URLs from Pocket:\n",
            " - https://huggingface.co/blog/starcoder?utm_source=pocket_saves\n",
            " - https://semianalysis.com/p/google-we-have-no-moat-and-neither?r=8ryw\n",
            " - https://kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html\n",
            " - https://vipshek.com/blog/gpt-learning?utm_source=tldrnewsletter\n",
            " - https://forefront.ai\n",
            " - https://aihits.co\n",
            " - https://stackoverflow.blog/2023/05/01/ai-isnt-the-app-its-the-ui?utm_source=tldrnewsletter\n",
            " - https://archive.ph/MPNuK\n",
            " - https://diamandis.com/blog/no-programmers\n",
            " - https://yourway.substack.com/p/ai-vs-humans-a-noise-audit-in-decision\n",
            " - https://hackernoon.com/how-ai-bots-code-comparing-bing-claude-co-pilot-gpt-4-and-bard\n",
            " - https://tweakers.net/nieuws/209238/openai-sommeert-student-om-te-stoppen-met-github-repo-gpt4free.html\n",
            " - https://theverge.com/2023/4/28/23702883/chatgpt-italy-ban-lifted-gpdp-data-protection-age-verification?utm_source=www.theaivalley.com&utm_medium=newsletter&utm_campaign=text-to-video-is-getting-insanely-powerful\n",
            " - https://themoscowtimes.com/2023/04/24/russias-sberbank-launches-own-version-of-chatgpt-a80921\n",
            " - https://techrepublic.com/article/chatgpt-cheat-sheet?utm_source=mail.koalapalooza.com&utm_medium=newsletter&utm_campaign=elon-s-paradoxical-pursuit-of-ai\n",
            " - https://wired.com/story/nsa-rob-joyce-chatgpt-security?utm_source=mail.koalapalooza.com&utm_medium=newsletter&utm_campaign=elon-s-paradoxical-pursuit-of-ai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, try to fetch all the content from the urls and summarize it with GPT.\n",
        "\n",
        "‚ö†Ô∏è Disclaimer: some websites might be unavailable or block our crawler on purpose."
      ],
      "metadata": {
        "id": "hY1X6nHPA-0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scrape the articles and summarize using OpenAI.\n",
        "\n",
        "%autoreload\n",
        "from next_in_ai.BatchSummarizer import BatchSummarizer\n",
        "\n",
        "batch_summarizer = BatchSummarizer(latest_pocket_urls)\n",
        "batch_summarizer.create_summary_document(debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoBIWSZ0-VJc",
        "outputId": "dbfd2ba0-1bcc-45a0-ffb1-48e6633a2f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.downloads:retries/redirects: https://semianalysis.com/p/google-we-have-no-moat-and-neither?r=8ryw HTTPSConnectionPool(host='semianalysis.com', port=443): Max retries exceeded with url: /p/google-we-have-no-moat-and-neither?r=8ryw (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f6c9947dd50>: Failed to establish a new connection: [Errno -5] No address associated with hostname'))\n",
            "ERROR:trafilatura.utils:lxml parsing failed: Document is empty\n",
            "ERROR:trafilatura.core:empty HTML tree for URL None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Creating the summary document\n",
            "\n",
            "\n",
            "Summarizing article:  https://huggingface.co/blog/starcoder?utm_source=pocket_saves\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://semianalysis.com/p/google-we-have-no-moat-and-neither?r=8ryw\n",
            "üåé Getting the contents of the url.\n",
            "<next_in_ai.OpenAISummarizer.OpenAISummarizer object at 0x7f6c9947d690> None\n",
            "‚ùå Couldn't fetch content from https://semianalysis.com/p/google-we-have-no-moat-and-neither?r=8ryw\n",
            "\n",
            "\n",
            "Summarizing article:  https://kdnuggets.com/2023/05/hugginggpt-secret-weapon-solve-complex-ai-tasks.html\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://vipshek.com/blog/gpt-learning?utm_source=tldrnewsletter\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://forefront.ai\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://aihits.co\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://stackoverflow.blog/2023/05/01/ai-isnt-the-app-its-the-ui?utm_source=tldrnewsletter\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://archive.ph/MPNuK\n",
            "üåé Getting the contents of the url.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:trafilatura.downloads:retries/redirects: https://archive.ph/MPNuK HTTPSConnectionPool(host='archive.ph', port=443): Max retries exceeded with url: /MPNuK (Caused by ResponseError('too many 429 error responses'))\n",
            "ERROR:trafilatura.utils:lxml parsing failed: Document is empty\n",
            "ERROR:trafilatura.core:empty HTML tree for URL None\n",
            "ERROR:trafilatura.downloads:retries/redirects: https://diamandis.com/blog/no-programmers HTTPSConnectionPool(host='diamandis.com', port=443): Max retries exceeded with url: /blog/no-programmers (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1007)')))\n",
            "ERROR:trafilatura.utils:lxml parsing failed: Document is empty\n",
            "ERROR:trafilatura.core:empty HTML tree for URL None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<next_in_ai.OpenAISummarizer.OpenAISummarizer object at 0x7f6c9947eb90> None\n",
            "‚ùå Couldn't fetch content from https://archive.ph/MPNuK\n",
            "\n",
            "\n",
            "Summarizing article:  https://diamandis.com/blog/no-programmers\n",
            "üåé Getting the contents of the url.\n",
            "<next_in_ai.OpenAISummarizer.OpenAISummarizer object at 0x7f6c9947ef20> None\n",
            "‚ùå Couldn't fetch content from https://diamandis.com/blog/no-programmers\n",
            "\n",
            "\n",
            "Summarizing article:  https://yourway.substack.com/p/ai-vs-humans-a-noise-audit-in-decision\n",
            "üåé Getting the contents of the url.\n",
            "<next_in_ai.OpenAISummarizer.OpenAISummarizer object at 0x7f6c9947ea10> AI vs. Humans: A Noise Audit in Decision-Making\n",
            "How Large Language Models exhibit lower levels of noise compared to human decision makers.\n",
            "TL;DR\n",
            "This article describes a study of noise audit in business decision making conducted with GPT-3.5-turbo and GPT-4 and with 52 human subjects. The results show that noise in LLMs is low, although it tends to increase with \"temperature\" (a setting in LLM API). It's also shown that decision noise is noticeably higher in the human results, which shows that LLMs can be applicable for business decision-making.\n",
            "Research Overview\n",
            "I conducted this research together with Professor Virginia Cha of the National University of Singapore (NUS) - a well known expert in innovation and business decision making.\n",
            "We wanted to find out if LLMs are susceptible to decision noise, and we compared them to 52 human participants in the EMBA program.\n",
            "I've already published several articles on the topic of decision noise - the latest one is here. Here‚Äôs another wonderful article on HRB on the same topic.\n",
            "In short, Noise, as described in the book \"Noise: A Flaw in Human Judgment\" by Daniel Kahneman, Olivier Sibony, and Cass R. Sunstein, refers to the unwanted variability in judgments that should be consistent in similar cases. In decision making, people often exhibit high levels of noise, leading to inconsistent judgments. Large language models, such as the GPT family of systems, are increasingly used for decision-making tasks. Therefore, it's important to understand the noise that these LLMs exhibit at different temperatures and using different models.\n",
            "Experimental design\n",
            "The experiment was designed to test the level of noise in decision making in GPT-3.5 and GPT-4 by conducting a noise audit. To do this, 20 business-related questions were created that covered four categories: Rating or Scoring Questions, Categorical Questions, Estimation Questions, and Decision Thresholds. The questions were related to a fictitious company (TechSolutions Inc.) that was described in enough detail to allow for guesswork.\n",
            "LLMs were asked the questions five times for each individual combination of temperature and model, resulting in 2000 data points. Human participants who were unaware of the noise audit were asked the same questions via a Google form as a task. All non-numeric responses were removed from the data set.\n",
            "As mentioned earlier, all questions were related to the fictitious company TechSolutions Inc. which was described in enough detail that one could make a guess at each question. You can find the description of the company below:\n",
            "(Scroll down to Results Analysis to see the results)\n",
            "TechSolutions Inc. is a mid-sized technology company specializing in software solutions for the healthcare sector. The company was founded in 2015 and has experienced significant growth over the years, currently generating $50 million in annual revenue. They have a diverse range of products and services, including electronic health record (EHR) systems, telemedicine platforms, and healthcare data analytics tools.\n",
            "In the past fiscal year, TechSolutions Inc. reported a 15% increase in revenue, amounting to $7.5 million, and a 12% increase in net profit, totaling $4.5 million. The company's current market share is at 20%, with three major competitors holding a combined market share of 70%. Their most recent product launch, the TeleHealth platform, resulted in a 10% increase in sales, bringing in an additional $5 million in revenue, and received 80% positive customer feedback.\n",
            "TechSolutions Inc. has a workforce of 200 employees, with 60 employees working in research and development, 80 employees in sales and marketing, and the remaining 60 employees in administrative and support roles. The company provides regular training and development opportunities for its employees, with a focus on leadership and technical skills. The average tenure of employees at TechSolutions Inc. is 3.5 years, and the company has a 90% retention rate.\n",
            "The company is considering several new projects for the next fiscal year, including an expansion into the European market, which is projected to generate an additional $10 million in annual revenue. They are also exploring the development of a new EHR system for small healthcare practices, aiming to capture 10% of this niche market, and a healthcare data analytics platform targeting insurance companies, which is forecasted to add another $8 million in revenue within two years. TechSolutions Inc. also plans to raise $15 million in additional funding to support these projects, either through equity investments or business loans.\n",
            "The company's current cash reserves are at $10 million, with a long-term debt of $5 million at an average interest rate of 4%. TechSolutions Inc.'s gross profit margin is 60%, and its operating margin is 30%. The company has an annual R&D budget of $3 million, a marketing budget of $4 million, and allocates 10% of its revenue to employee training and development.\n",
            "Then 20 questions were created - 5 in each of the categories. Here‚Äôs a list of categories and questions that were used for this test:\n",
            "Rating or Scoring Questions\n",
            "Considering TechSolutions Inc.'s financial performance, market presence, and employee development initiatives, rate the company's overall attractiveness as an investment opportunity on a scale of 1 to 10.\n",
            "On a scale of 1 to 10, how would you rate TechSolutions Inc.'s overall performance in the past fiscal year, considering their revenue growth, net profit increase, and market share?\n",
            "Considering the 10% increase in sales and 80% positive customer feedback, rate the success of the TeleHealth platform launch on a scale of 1 to 5.\n",
            "Based on the company's employee training and development opportunities, rate the effectiveness of its talent development strategy on a scale of 1 to 10.\n",
            "On a scale of 1 to 5, how well do you think TechSolutions Inc. is positioned to compete with the three major competitors in the healthcare software market?\n",
            "Categorical Questions\n",
            "Based on TechSolutions Inc.'s current financial situation and growth prospects, which of the following strategies should the company prioritize? Please choose one option: (1) Focus on organic growth through reinvesting profits (2) Pursue inorganic growth through mergers and acquisitions (3) Combine organic growth with selective mergers and acquisitions (4) Diversify into new markets while maintaining current growth strategies\n",
            "Considering TechSolutions Inc.'s product portfolio and market presence, should the company primarily focus on (1) enhancing its existing products and services, or on (2) developing new and innovative solutions for the healthcare sector?\n",
            "Given the company's current financial situation, should TechSolutions Inc. seek additional funding through (1) equity investments, (2) business loans, or (3) a combination of both?\n",
            "Based on the company's growth strategy, should TechSolutions Inc. prioritize (1) expansion into the European market, (2) developing the new EHR system, or (3) creating the healthcare data analytics platform?\n",
            "Considering the company's current employee structure, should TechSolutions Inc. (1) hire more employees in research and development, (2) sales and marketing, or (3) administrative and support roles?\n",
            "Estimation Questions\n",
            "Assuming TechSolutions Inc. successfully expands into the European market, estimate the percentage of total company revenue that will be generated from this new market within the first two years.\n",
            "Given the TechSolutions Inc. 15% increase in revenue and 12% increase in net profit, estimate TechSolutions Inc.'s potential net profit growth in the next fiscal year (in percentage).\n",
            "Considering the company's current market share of 20% and the competitors' combined market share of 70%, estimate TechSolutions Inc.'s potential market share in the next three years (in percentage).\n",
            "Given the TechSolutions Inc. plans to raise additional funding, estimate the percentage of funds that should be allocated to the following project: Healthcare data analytics platform targeting insurance companies.\n",
            "Based on the company's current workforce distribution (30% in R&D, 40% in sales and marketing, and 30% in administrative and support roles), estimate the percentage increase in the workforce required for sales and marketing department to support the company's growth over the next three years.\n",
            "Decision Thresholds\n",
            "TechSolutions Inc. is planning to expand its product line. What is the minimum projected annual revenue increase (in percentage) that would justify the development and launch of a new product in the healthcare software market?\n",
            "TechSolutions Inc. is considering raising additional funding through business loans. At what annual interest rate (in percentage) would you recommend not pursuing this funding option?\n",
            "TechSolutions Inc. is evaluating the potential return on investment (ROI) for the new EHR system project. What is the minimum ROI (in percentage) the company should expect to justify pursuing the project?\n",
            "Assuming TechSolutions Inc. needs to raise $5 million to fund its expansion plans, what is the maximum percentage of company ownership that it should be willing to give up in exchange for the required funding, considering its current valuation of $25 million?\n",
            "TechSolutions Inc. currently has a customer satisfaction rate of 85% for its products. In order to maintain its market position and strengthen customer loyalty, what should be the minimum percentage of positive customer feedback the company should aim for in the upcoming year?\n",
            "After formulating the questions, I queried the OpenAI API to ask GPT-3.5-turbo and GPT-4 each of these questions along with the context and the various temperature settings from 0.0 to 1.0.\n",
            "Each API call was context independent, i.e., LLM didn't know that other questions had been answered previously. Each question was asked in the following order:\n",
            "messages=[ {\"role\": SYSTEM, \"content\": company_description}, {\"role\": SYSTEM, \"content\": \"Your task is to give the best estimate of the answer the provided questions based on the given context to the best of your ability. You must only return an INTEGER number.\"}, {\"role\": USER, \"content\": question+\"\\\\n\\\\n I NEED YOU TO PROVIDE A CONCISE ANSWER TO THE ABOVE QUESTION. RETURN ONLY MACHINE-READABLE ANSWER, NO EXPLANATION REQUIRED. ONLY A NUMER.\"} ]\n",
            "(full code can be found in the resources section)\n",
            "Results Analysis\n",
            "Results were first adjusted for outliers using the interquartile range method with 1.5 IQR and then normalized to a range of 0 to 1 to allow comparisons between questions with different scales. Basically, we just made sure that the data were clean and comparable.\n",
            "I created scatter plots and standard deviation plots for both the GPT-4 and the GPT-3.5 and for the human participants. These plots show that increasing the temperature for LLMs increases the standard deviation for some questions. There wasn't much difference between GPT-4 and GPT-3.5 in terms of deviation of responses at different temperatures, with a few exceptions for certain questions.\n",
            "For several questions, both models showed complete agreement of answers and no noise, while for some other questions at least one of the systems showed a complete absence of noise. Only for a few questions did the LLMs show a relatively high level of noise as measured by the standard deviation of the responses.\n",
            "For the human participants, however, the standard deviation of responses was much more spread out:\n",
            "Comparing the standard deviation of responses for humans, GPT-4, and GPT-3.5, we find that humans have a higher average standard deviation (16.4%) than LLMs (GPT-4: 4.1%, GPT-3.5: 5.5%).\n",
            "I then created a line chart showing the average noise by temperature for LLMs. Note that the self-assessed power level was used as the \"temperature\" for people. This is obviously not comparable, but it's the only way I could think of to compare LLMs to humans in a table. That is where you can clearly see the dynamics of the LLMs noise levels, as well as average noise values for human participants.\n",
            "Conclusions\n",
            "In the end, then, we see that both the GPT-3.5 and GPT-4 Large Language Models have lower noise compared to human decision makers in the EMBA program (4.1% and 5.5%, respectively, for LLMs versus 16.4% on average for humans). (Direct comparison of LLM noise results to human noise is difficult because we're comparing ensemble probability (for humans) to time probability (for LLMs). This only gives a directional estimate. A more accurate comparison would be possible if we received the answers to the same question multiple times from the same person without recollection). The noise in the LLMs increases with higher temperature settings, consistent with the hypothesis that higher temperatures introduce more randomness into the model's results. However, despite this increase, the noise in the LLMs remained lower than in the human participants.\n",
            "The similarity in performance between GPT-4 and GPT-3.5 suggests that the improvements in the architecture of GPT-4 over its predecessor didn't result in a significant reduction in noise. It's important to note that while LLMs have lower noise levels than human participants, this doesn't necessarily mean that they always make better or more accurate decisions. LLMs still rely on the information they have been trained on, which isn't always applicable to the specific context of a given problem.\n",
            "The key takeaway from this experiment is that, at least from a decision noise perspective, the LLMs tested are pretty good on their own and compared to humans. This brings them one step closer to becoming effective decision-makers under uncertainty.\n",
            "I write about AI & Decision-making. Subscribe for free to receive new posts and support my work.\n",
            "Business Implications\n",
            "Everyone is talking about applications of AI in our daily lives and in business. Research like this consistently shows that AI's thinking and decision-making capabilities are growing and, in some cases (like this one), surpassing those of humans. This means that these systems will inevitably find their way into daily business processes, not only to automate daily work, but also to make management decisions.\n",
            "However, there are still many serious problems to be solved before this can happen, the most important of which I consider to be:\n",
            "Hallucinations. LLMs can confidently make mistakes - they still tend to hallucinate and give confident but wrong answers when they don't know certain things.\n",
            "Size of context. The best decisions take into account a large context of diverse information. Much of this context is difficult to verbalize (e.g., the body language of a business partner at a recent meeting). And for the information that can be verbalized, the \"information window\" for LLMs is limited by the maximum number of tokens that can be shared there.\n",
            "Lack of accountability. As AI agents become more involved in enterprise decision making, it can become more difficult to assign responsibility when mistakes occur, complicating liability issues.\n",
            "Bias and discrimination: AI agents may unintentionally perpetuate existing biases in training data, leading to unfair or discriminatory decisions.\n",
            "At this point, however, the future seems inevitable - AI agents will be used for decision-making tasks with increasing frequency and quality.\n",
            "Future Research Directions\n",
            "Although this study provides a solid foundation for understanding noise levels in LLMs, further research is needed to extend these findings. Future studies could investigate the following aspects:\n",
            "The effects of domain-specific fine-tuning on noise reduction in LLMs.\n",
            "Investigate possible correlations between question types and noise levels in LLMs and whether certain question types are more susceptible to noise.\n",
            "The relationship between LLMs' confidence in their responses and the actual noise level in those responses.\n",
            "The use of ensemble approaches to combine the results of multiple LLMs to reduce noise and improve decision accuracy.\n",
            "By further exploring the capabilities and limitations of LLMs in decision making, researchers can continue to improve the practical applications of these powerful AI systems and unlock their potential to revolutionize industries and improve human decision making.\n",
            "Resources\n",
            "Raw answers from the LLM and students, along with the code used for execution and analysis of this study can be found on GitHub.\n",
            "Thanks for reading Your Way - AI & Decision-making! Subscribe for free to receive new posts and support my work.\n",
            "‚è≥ Summarizing the text.\n",
            "This model's maximum context length is 4097 tokens. However, you requested 4117 tokens (3717 in the messages, 400 in the completion). Please reduce the length of the messages or completion.\n",
            "\n",
            "‚ùå Couldn't summarize the text, probably too long. \n",
            "\n",
            "\n",
            "Summarizing article:  https://hackernoon.com/how-ai-bots-code-comparing-bing-claude-co-pilot-gpt-4-and-bard\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://tweakers.net/nieuws/209238/openai-sommeert-student-om-te-stoppen-met-github-repo-gpt4free.html\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://theverge.com/2023/4/28/23702883/chatgpt-italy-ban-lifted-gpdp-data-protection-age-verification?utm_source=www.theaivalley.com&utm_medium=newsletter&utm_campaign=text-to-video-is-getting-insanely-powerful\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://themoscowtimes.com/2023/04/24/russias-sberbank-launches-own-version-of-chatgpt-a80921\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://techrepublic.com/article/chatgpt-cheat-sheet?utm_source=mail.koalapalooza.com&utm_medium=newsletter&utm_campaign=elon-s-paradoxical-pursuit-of-ai\n",
            "ü§ó Got summary from cache.\n",
            "\n",
            "\n",
            "Summarizing article:  https://wired.com/story/nsa-rob-joyce-chatgpt-security?utm_source=mail.koalapalooza.com&utm_medium=newsletter&utm_campaign=elon-s-paradoxical-pursuit-of-ai\n",
            "ü§ó Got summary from cache.\n",
            "‚úÖ Writing summaries to file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the resulting .docx\n",
        "from google.colab import files\n",
        "import datetime\n",
        "\n",
        "date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "output_filename = f\"summaries-{date_str}.docx\"\n",
        "files.download(f\"/content/{output_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "bw8fRT9LElxY",
        "outputId": "fa751a78-80d3-4f43-b041-ba3dfdf127fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dcb15c1b-1c5d-4d9a-991e-50416f0c8fd3\", \"summaries-2023-05-05.docx\", 42904)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}